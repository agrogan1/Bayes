---
title: "A Discussion Focused, Collaborative, Lab-Based Introduction to Bayesian Statistics"
subtitle: "*Thinking about* Bayesian analysis can be HARD. *Doing* Bayesian analysis can be EASY! 'Fail Frequently! Fail Forward!'"
title-slide-attributes:  
  data-background-image: mountains.png
author: "Andy Grogan-Kaylor"
date: "today"
format: 
  revealjs:
    scrollable: true
    transition: convex
    controls: true
    controls-tutorial: true
    navigation-mode: vertical
    slide-number: h.v
    chalkboard: true
    logo: Thomas_Bayes.png
execute: 
  freeze: auto
---

# Navigation 

```{css, echo = FALSE}

h1.title, .quarto-title-author-name, p.date {
  font-size: 50px;
  color: white;
  background-color: purple; 
}

#title-slide .subtitle, div.reveal div.slides section.quarto-title-block .subtitle {
  color: white;
  background-color: purple; 
}

```

* **o** for outline
* **f** for full screen
* **Alt-Click** to zoom
* Scroll &#8681; to the bottom of each column of slides; then &#8680;

# Beginning (10 Minutes)

## Background

::: {layout="[1,1]" layout-valign="bottom"}
![Thomas Bayes](Thomas_Bayes.png)

![Pierre-Simon Laplace](Laplace_Pierre-Simon.png)
:::

Bayesian statistics are often touted as the *new statistics*, that should perhaps supplant traditional *frequentist* statistics. 

## Advantages {.smaller}

Bayesian statistics have the advantage of being able to incorporate prior information (e.g. clinical wisdom & insight, community knowledge, results of meta-analyses and literature reviews). 

Bayesian statistics also have the advantage that we are not simply deciding whether to reject the null hypotheses, $P(D|H_0)$ but are rather able to evaluate the probability of a hypothesis, $P(H|D)$. In essence, this means that we can sometimes decide to *accept* the null hypothesis, rather than *failing to reject the null hypothesis*.

## Disadvantages {.smaller}

However, Bayesian statistics may be very difficult to understand. Further, while statistical software for Bayesian inference is becoming easier and easier to use, syntax for Bayesian inference may remain complicated and counter-intuitive 

::: {.fragment .highlight-red}
Lastly, the advantages of being able to *incorporate prior information* and to *accept the null hypothesis* may be overstated: *prior information* may be difficult to come by; and social science may be able to move forward quite well without the ability to *accept null hypotheses*.
:::

In this presentation I hope to at least introduce some of these ideas, and to generate some discussion of them. 

# Bayes' Theorem As Equation & Words (10 Minutes) {.smaller}

10 minutes is *far too short a time* to talk about how the mathematics of Bayes' theorem imply, and connect to, all of the ideas that we will discuss in this presentation. Nevertheless, a presentation on Bayesian statistics would be incomplete without some reference to Bayes' theorem. In this presentation, we gesture quickly at Bayes' theorem to demonstrate that Bayes' theorem contains at least two key ideas: We are estimating the probability of hypotheses; and we are using prior information. Discussion in later slides will connect us back to some of these ideas. 

## Equation 

$$P(H|D) = \frac{P(D|H) P(H)}{P(D)}$$ 

## Words

$$\text{posterior} = \frac{\text{likelihood} \times \text{prior}}{\text{data}}$$

$$\text{posterior} \propto \text{likelihood} \times \text{prior}$$ 

## In Even More Words: 

Our posterior (updated) beliefs about the probability of some hypothesis are proportional to our prior beliefs about the probability of that hypothesis multiplied by the likelihood that were our hypothesis true it would have generated the data we observe.

# Why Do We Care / Should We Care? (40 Minutes Total)

## Prior Information (20 Minutes)

[https://agrogan.shinyapps.io/Thinking-Through-Bayes/](https://agrogan.shinyapps.io/Thinking-Through-Bayes/)

## Accepting The Null Hypothesis (20 Minutes, If Time) {.smaller background-color="lightgrey"}

In Bayesian analysis, we are *not* assessing the plausibility of the data ($P(D|H)$), given the assumption of a null hypothesis $H_0: \text{parameter value} = 0$. This feature of Bayesian analysis has a few key implications:

* We are actually estimating--*the probability of a particular hypothesis given the data*--what we often *think* we are estimating in Frequentist analysis. Thus, after conducting a Bayesian analysis, we can simply say, "The probability of our hypothesis ($P(H|D)$) given the data is *x*," rather than engaging in complicated statements about "Were the null hypothesis to be true, we estimate that it is *p* likely that we would see data as extreme, or more extreme, than we actually observed."
    
* Because we are directly estimating the probability of hypotheses, we can not only evaluate the probability of the null hypothesis ($H_0$), but also accept the null hypothesis ($H_0$), something that we are never supposed to be able to do in frequentist analysis. Being able to accept the null hypothesis may have implications for *equivalency testing* and *theory simplification* and may reduce publication bias, if we are not always looking for ways to reject $H_0$.
    
[https://agrogan1.github.io/Bayes/accepting-H0/accepting-H0.html](https://agrogan1.github.io/Bayes/accepting-H0/accepting-H0.html)
    
# Lab and Questions (Work At Your Own Pace and Leave When You're Done) (Last 60 Minutes)

Thinking through Bayes is *hard*. We perhaps learn best by doing.

## Our Data {.smaller}

We are using simulated data from my text on multilevel modeling, *Multilevel Thinking*: [https://agrogan1.github.io/multilevel-thinking/simulated-multi-country-data.html](https://agrogan1.github.io/multilevel-thinking/simulated-multi-country-data.html).

This simulated data comes from multiple countries so we use `mixed` instead of `regress` to account for the clustering. However, our process would be largely the same if we were to use `regress.`

```{r}

library(Statamarkdown)

```

```{stata, echo = TRUE, collectcode = TRUE}

set seed 3846

use "https://github.com/agrogan1/multilevel-thinking/raw/main/simulate-and-analyze-multilevel-data/simulated_multilevel_data.dta"

```

## Basic Bayesian Regression {.smaller}

What do the results say (particularly about HDI)?

```{stata, echo=TRUE, eval=TRUE}

bayes: mixed outcome physical_punishment warmth HDI || country:

```

## Bayesian Regression With Prior {.smaller}

Here we state our prior beliefs about the $\beta_{HDI} HDI$

We think it is 1, but put some uncertainty around that belief ($sd = 10$)

```{stata, echo=TRUE, eval=TRUE}

bayes, prior({outcome:HDI}, normal(1,10)): mixed outcome physical_punishment warmth HDI || country: 

```

# Questions? {background-color="black"}




