---
title: "Bayesian and Frequentist Multilevel Modeling"
author: "Andy Grogan-Kaylor"
date: "`r Sys.Date()`"
output:
  html_document: 
    fig_height: 3
    highlight: haddock
    number_sections: yes
    toc: yes
    toc_float:
      collapsed: yes
      smooth_scroll: yes
  tufte::tufte_handout:
    highlight: haddock
    number_sections: yes
    toc: yes
  tufte::tufte_html: 
    highlight: haddock
    number_sections: yes
    toc: yes
  tint::tintPdf:
    highlight: haddock
    number_sections: yes
    toc: yes
    latex_engine: xelatex
header-includes: \usepackage{draftwatermark}
bibliography: ["Bayesian-and-frequentist-MLM.bib"]
biblio-style: "apalike"
link-citations: true
---

<style>
h1, h2 {
  color: navy;
  font-family: "Helvetica", "Arial", sans-serif; 
  font-weight: normal;
}
.list-group-item.active, 
.list-group-item.active:focus, 
.list-group-item.active:hover {
    z-index: 2;
    color: gold;
    background-color: navy;
    border-color: blue;
}
.nav-pills > li.active > a, .nav-pills > li.active > a:focus {
    color: gold;
    background-color: navy;
}
.nav-pills > li.active > a:hover {
    color: gold;
    background-color: navy;

}
</style>

\SetWatermarkText{ROUGH DRAFT}
\SetWatermarkFontSize{3cm}

```{r setup, include=FALSE}

library(tint)

# invalidate cache when the package version changes

knitr::opts_chunk$set(tidy = FALSE, 
                      # cache.extra = packageVersion('tint'),
                      echo = FALSE,
                      warning = FALSE,
                      message = FALSE,
                      fig.margin = TRUE)

options(htmltools.dir.version = FALSE)

library(MASS)

library(ggplot2)

library(ggthemes)

```

# Introduction

$$y_{ij} = \beta_0 + \beta_1 x_{1i} + u_{0j} + e_{ij}$$

All multilevel models account for group structure, in estimating the association of $x$ and $y$.

Bayesian models may offer some advantages over frequentist models, but may be substantially slower to converge.

# Prior Information

Bayesian models allow one to incorporate prior information about a parameter of interest.

Prior information may come from the prior research literature, e.g. from systematic reviews or meta-analyses, or expert opinion or clinical wisdom.

# Smaller Samples

Bayesian multilevel models may be better with small samples, especially samples with small numbers of Level 2 units [@Hox2012]. It is not clear to what degree this improvement in performance is dependent upon the use of informative priors.

# Full Distribution of Parameters

Bayesian models of all kinds provide full distributions of the parameters (e.g. $\beta$'s and random effects ($u$'s))--both singly and jointly--rather than only point estimates.

```{r, fig.height=3, fig.cap="Distribution of a Single Parameter"}

beta1 <- rbeta(10000, 1.0, 2.5)

ggplot(data = NULL,
       aes(x = beta1)) + 
  geom_density(fill="blue", alpha = .25) +
  geom_vline(xintercept = median(beta1)) +
  geom_text(aes(x=median(beta1), 
                label="\nmedian", y = 1), 
            colour="red", 
            angle= -90) +
  theme_tufte() + 
  labs(title = "Distribution of \u03b2",
       subtitle = "\u03b2 is Skewed",
       x = "\u03b2") 

```

```{r, fig.height=3, fig.cap="Joint Distribution of Parameters"}

# inspired by a coding approach at
# https://stackoverflow.com/questions/11530010/how-to-simulate-bimodal-distribution

# u0

u0 <- rnorm(1000, 0.5, 2)

# u1

u1a <- rnorm(1000, 0, .1)

u1b <- rnorm(1000, 1, .1)

flag <- rbinom(1000, size=1, prob=.5)

u1 <- u1a * (1 - flag) + u1b * flag 

# density plot

mydensity <- kde2d(u0, u1)

par(mar = rep(2, 4)) # adjust margins

persp(mydensity,
      theta = -45,
      phi = 10,
      main = "Distribution of Random Effects",
      xlab = "random intercept",
      ylab = "random slope",
      zlab = "probability",
      lwd = .5)

# pairs(data.frame(beta1,beta2))

# library(GGally)
# 
# ggpairs(data.frame(beta1,beta2),
#         lower = list(continuous = "density"))

```

# Accepting $H_0$ is Possible

Bayesian models allow one to both accept and reject $H_0$ [@Kruschke2018]. This may have consequences for affirming similarity, universality, or treatment invariance [@Morey2018]. 

Also, accepting certain null hypotheses may allow for the simplification of theory.

# Distributional Models

Bayesian estimators allow one to directly model $\sigma_{u_0}$, the variance of the Level 2 units as a function of covariates [@Burkner2018].

# Non-Linear Terms

```{r, fig.cap="Non-Linear Terms"}

# options(scipen = 999)

x <- rnorm(100, 0, 10)

e <- rnorm(100, 0, 1000)

y <- x^3 + e

ggplot(data=NULL,
       aes(x = x,
           y = y)) + 
  geom_point() + 
  geom_smooth() +
  labs(title = "Non-Linear Smoother") +
  # theme_minimal()
  theme_tufte()

```


Bayesian estimators allow for the incorporation of non-linear terms [@Burkner2018].[^overfitting]

[^overfitting]: Such non-linear terms offer ways of non-parametrically fitting curvature. Do they represent over-fitting? Do they provide substantively interpretable results?

# Maximal Models

Bayesian estimators allow for the inclusion of a large number of random slopes, e.g. $u_1, u_2, u_3, ..., etc.$ even when some of those estimated slopes are close to 0.

# References






