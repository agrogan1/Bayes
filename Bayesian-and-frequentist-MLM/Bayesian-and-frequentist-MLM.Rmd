---
title: "Bayesian and Frequentist Multilevel Modeling"
author: "Andy Grogan-Kaylor"
date: "`r Sys.Date()`"
output:
  tint::tintPdf:
    toc: yes
    number_sections: yes
    latex_engine: xelatex
  distill::distill_article:
    highlight: haddock
    toc: yes
  pdf_document: 
    fig_height: 3
    highlight: haddock
    latex_engine: xelatex
    number_sections: yes
    toc: yes
link-citations: yes
bibliography: Bayesian-and-frequentist-MLM.bib
biblio-style: apalike
citation_url: https://agrogan1.github.io/Bayes/Bayesian-and-frequentist-MLM/Bayesian-and-frequentist-MLM.html
---

```{r setup, include=FALSE}

library(tint)

# invalidate cache when the package version changes

knitr::opts_chunk$set(tidy = FALSE, 
                      # cache.extra = packageVersion('tint'),
                      echo = FALSE,
                      warning = FALSE,
                      message = FALSE,
                      fig.margin = TRUE)

options(htmltools.dir.version = FALSE)

library(MASS)

library(ggplot2)

library(ggthemes)

```

# Introduction

```{r, fig.height=3, fig.cap="Simulated Multilevel Model"}

N1 <- 100 # L1 sample size

N2 <- 10 # L2 sample size

x <- rnorm(N1, 100, 10)

e <- rnorm(N1, 0, 10)

u0 <- rnorm(N2, 0, .5)

u0 <- rep(u0, 10, each = 10)

u1 <- rnorm(N2, 0, .5)

u1 <- rep(u1, 10, each = 10)

group <- rep(seq(1,10), each = 10)

group <- factor(group)

y <- x + e + u0 + u1 * x # regression relationship

mydata <- data.frame(x, e, u0, u1, y, group)

library(ggplot2)

ggplot(data = mydata,
       aes(x = x,
           y = y)) +
  geom_point(aes(color = group)) +
  geom_smooth(aes(color = group), method = "lm") +
  geom_smooth(aes(color="overall"),
              method = "lm") +
  theme_minimal() +
  scale_color_viridis_d() +
  labs(title = "Multilevel Model")

```


$$y_{ij} = \beta_0 + \beta_1 x_{1i} + u_{0j} + u_{1j} x + e_{ij}$$

All multilevel models account for group structure, in estimating the association of $x$ and $y$, by including a random intercept ($u_0$), and possibly one or more random slope terms ($u_1, u_2, etc....$).

Bayesian models may offer some advantages over frequentist models, but may be *substantially* slower to converge.

# Conceptual Appropriateness

Following Kruschke [-@Kruschke2014] all Bayesian models have a *conceptual appropriateness*. 

In frequentist reasoning we are estimating the probability of observing data at least as extreme as our data, while assuming a null hypothesis ($H_0$). As has been noted, $H_0$, *e.g.* $\beta = 0$, or $\bar{x}_A - \bar{x}_B = 0$, is very often not a substantively interesting or substantively meaningful hypothesis. 

In Bayesian analysis, we are not rejecting a null hypothesis. Instead, we are *directly estimating the value of a parameter* such as $\beta$ and are indeed estimating a *full probability distribution* for this parameter.

# Accepting the Null Hypothesis ($H_0$)

The Bayesian approach means that we have the ability to accept the null hypothesis $H_0$ [@Kruschke2018]. This ability to accept $H_0$ might possibly lead to theory simplification [@Gallistel2009; @Morey2018], as well as to a lower likelihood of the publication bias that results from frequentist methods predicated upon the rejection of $H_0$ [@Kruschke2018].

# Model Comparison

Relatedly, Bayesian approaches allow one to compare an alternative model $H_A$ with a null model $H_0$, or to simply compare two alternative statistical models ($H_1$ vs. $H_2$). Bayesian models may have a better perspective on these kinds of statistical comparisons than do frequentist approaches. As Jarosz et al. [-@Jarosz2014] note: 

> "All Bayesian approaches are comparisons of models. This means that a Bayes factor considers the likelihood of both the null and the alternative hypothesis. From the researcherâ€™s standpoint, this is likely closer to their overall goal than simply rejecting the null hypothesis."

# Prior Information

Bayesian models allow one to incorporate prior information about a parameter of interest.

Prior information may come from the prior research literature, e.g. from systematic reviews or meta-analyses, or expert opinion or clinical wisdom.

Kruschke [-@Kruschke2014] points out that "No analysis is immune to false alarms, because randomly sampled data will occasionally contain accidental coincidences of outlying values." However, according to Kruschke [-@Kruschke2014] careful use of priors may reduce the probability of false alarms.

# Multiple Comparisons

As Kruschke [-@Kruschke2014] observes, multiple comparisons (especially when they are *post hoc*) are less of a concern for Bayesian analysis than they are for a frequentist analysis: 

> "In a Bayesian analysis, however, there is just one posterior distribution over the parameters that describe the conditions. That posterior distribution is unaffected by the intentions of the experimenter, and the posterior distribution can be examined from multiple perspectives however is suggested by insight and curiosity."

# Smaller Samples

Bayesian multilevel models may be better with small samples [@VandeSchoot2015], especially samples with small numbers of Level 2 units [@Hox2012]. Some of this advantage may occur when parameters are not normally distributed. It appears that much of this improvement in performance is dependent upon the use of informative priors [@Smid2020], and that Bayesian models with small samples may provide worse estimates than maximum likelihood estimates when less informative, or inaccurate, priors are used [@McNeish2016].

# Full Distribution of Parameters

Bayesian models of all kinds provide full distributions of the parameters (e.g. $\beta$'s and random effects ($u$'s))--both singly and jointly--rather than only point estimates.

Information about the full distribution of a parameter, such as the estimate of the probability distribution of values of a risk factor, a protective factor, or the effect of an intervention, may be substantively meaningful [@Rindskopf2020]. Such information may be especially important when the distribution of a regression parameter is non-normal [@VandeSchoot2014; @Finch2017] e.g. in smaller samples.

```{r, fig.height=3, fig.cap="Distribution of a Single Parameter"}

beta1 <- rbeta(10000, 1.0, 2.5)

ggplot(data = NULL,
       aes(x = beta1)) + 
  geom_density(fill="blue", alpha = .25) +
  geom_vline(xintercept = median(beta1)) +
  geom_text(aes(x=median(beta1), 
                label="\nmedian", y = 1), 
            colour="red", 
            angle= -90) +
  theme_minimal() + 
  labs(title = "Distribution of \u03b2",
       subtitle = "\u03b2 is Skewed",
       x = "\u03b2") 

```

```{r, fig.height=3, fig.cap="Joint Distribution of Parameters"}

# inspired by a coding approach at
# https://stackoverflow.com/questions/11530010/how-to-simulate-bimodal-distribution

# u0

u0 <- rnorm(1000, 0.5, 2)

# u1

u1a <- rnorm(1000, 0, .1)

u1b <- rnorm(1000, 1, .1)

flag <- rbinom(1000, size=1, prob=.5)

u1 <- u1a * (1 - flag) + u1b * flag 

# density plot

mydensity <- kde2d(u0, u1)

par(mar = rep(2, 4)) # adjust margins

persp(mydensity,
      theta = -45,
      phi = 10,
      main = "Joint Distribution of Random Effects",
      xlab = "random intercept",
      ylab = "random slope",
      zlab = "probability",
      lwd = .5)

# pairs(data.frame(beta1,beta2))

# library(GGally)
# 
# ggpairs(data.frame(beta1,beta2),
#         lower = list(continuous = "density"))

```

As Stata Corporation notes, "In a Bayesian multilevel model, *random effects* are model parameters just like regression coefficients and variance components" [@StataCorp2020].  This ability to estimate the *distributions* of these random effects means that the *distribution* of the random effect for one group can be compared to another. For example, the *distribution* of a parameter in one country could be directly compared to the *distribution* of that same parameter in another country. One could even estimate the probability that a particular $\beta$ had a higher value in one group (e.g. country), than in another. As Balov [-@Balov2016] suggests, this Bayesian approach allows us to "quantify the credibility" of these comparisons, which would not be possible with a frequentist approach.

As an example, Stunnenberg et al. [-@Stunnenberg2018] conducted a Bayesian analysis where the results of the multilevel analysis were used to inform treatment decisions. Here the data were repeated measures on patients, and thus the patients were the groups: "On completion of each treatment set, a Bayesian analysis was conducted to calculate the posterior probability of mexiletine [treatment] producing a clinically meaningful difference in the individual patient." 

# Distributional Models

Bayesian estimators allow one to directly model $\sigma_{u_0}$, the variance of the Level 2 units, as a function of covariates [@Burkner2018]. This *potentially* allows for the opportunity for this variation to become an outcome parameter of substantive interest.

# Non-Linear Terms

```{r, fig.height=3, fig.cap="Non-Linear Terms"}

# options(scipen = 999)

x <- rnorm(100, 0, 10)

e <- rnorm(100, 0, 1000)

y <- x^3 + e

ggplot(data=NULL,
       aes(x = x,
           y = y)) + 
  geom_point() + 
  geom_smooth() +
  labs(title = "Non-Linear Smoother") +
  theme_minimal()

```

Bayesian estimators allow for the incorporation of non-linear terms [@Burkner2018]. Such non-linear terms offer ways of non-parametrically fitting curvature. An open question is whether such methods represent a kind of over-fitting.  A related question is the degree to which non-linear terms provide substantively interpretable results.

```{r, echo=FALSE, eval=FALSE}

# Random Slopes Close to Zero

# There is some suggestion that Bayesian models may be better at estimating models with random slopes closer to 0.

```

# Maximal Models

Bayesian estimators allow for the estimation of so called *maximal models* [@Barr2013; @Frank2018], which allow for the inclusion of a large number of random slopes, e.g. $u_1, u_2, u_3, ..., etc.$ even when some of those estimated slopes are close to 0. 

It should be noted that  Matuschek et al. [-@Matuschek2017] argue that such a *maximal* approach may lead to a loss of statistical power and further argue that one should adhere to "a random effect structure that is supported by the data." In contrast, Nalborczyk et al. [-@nalborczyk_batailler_loevenbruck_vilain_bÃ¼rkner_2019] argue that maximal models are supported under the Bayesian approach.

```{r, echo=FALSE, results='asis'}

# print a reference header when not HTML5

if(knitr::opts_knit$get("rmarkdown.pandoc.to") != "html5") {
  
  cat("# References")
  
}

```








