@misc{StataCorp2020,
author = {StataCorp},
title = {Bayesian multilevel models},
url = {https://www.stata.com/features/overview/bayesian-multilevel-models/},
year = {2020}
}
@inproceedings{Balov2016,
author = {Balov, Nikolay},
booktitle = {2016 Stata Conference},
title = {Bayesian hierarchical models in Stata},
url = {https://ideas.repec.org/p/boc/scon16/30.html},
year = {2016}
}
@article{Kruschke2018,
abstract = {In the practice of data analysis, there is a conceptual distinction between hypothesis testing, on the one hand, and estimation with quantified uncertainty on the other. Among frequentists in psychology, a shift of emphasis from hypothesis testing to estimation has been dubbed ``the New Statistics'' (Cumming 2014). A second conceptual distinction is between frequentist methods and Bayesian methods. Our main goal in this article is to explain how Bayesian methods achieve the goals of the New Statistics better than frequentist methods. The article reviews frequentist and Bayesian approaches to hypothesis testing and to estimation with confidence or credible intervals. The article also describes Bayesian approaches to meta-analysis, randomized controlled trials, and power analysis.},
author = {Kruschke, John K. and Liddell, Torrin M.},
doi = {10.3758/s13423-016-1221-4},
issn = {1531-5320},
journal = {Psychonomic Bulletin {\&} Review},
month = {feb},
number = {1},
pages = {178--206},
title = {The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective},
url = {https://doi.org/10.3758/s13423-016-1221-4},
volume = {25},
year = {2018}
}
@book{Kruschke2014,
abstract = {There is an explosion of interest in Bayesian statistics, primarily because recently created computational methods have finally made Bayesian analysis obtainable to a wide audience. Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan provides an accessible approach to Bayesian data analysis, as material is explained clearly with concrete examples. The book begins with the basics, including essential concepts of probability and random sampling, and gradually progresses to advanced hierarchical modeling methods for realistic data. Included are step-by-step instructions on how to conduct Bayesian data analyses in the popular and free software R and WinBugs. This book is intended for first-year graduate students or advanced undergraduates. It provides a bridge between undergraduate training and modern Bayesian methods for data analysis, which is becoming the accepted research standard. Knowledge of algebra and basic calculus is a prerequisite.},
author = {Kruschke, John K.},
booktitle = {Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan, Second Edition},
doi = {10.1016/B978-0-12-405888-0.09999-2},
isbn = {9780124058880},
mendeley-groups = {Bayes},
month = {jan},
pages = {1--759},
publisher = {Elsevier Science},
title = {Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan, second edition},
year = {2014}
}
@article{Burkner2017,
author = {Burkner, Paul-Christian},
doi = {10.18637/jss.v080.i01},
journal = {Journal of Statistical Software},
number = {1},
pages = {1--28},
title = {brms: An R Package for Bayesian Multilevel Models Using Stan},
volume = {80},
year = {2017}
}
@article{Burkner2018,
author = {Burkner, Paul-Christian},
journal = {The R Journal},
number = {1},
pages = {395--411},
title = {Advanced Bayesian Multilevel Modeling with the R Package brms},
volume = {10},
year = {2018}
}
@article{Hox2012,
abstract = {Meuleman and Billiet (2009) have carried out a simulation study aimed at the question how many countries are needed for accurate multilevel SEM estimation in comparative studies. The authors concluded that a sample of 50 to 100 countries is needed for accurate estimation. Recently, Bayesian estimation methods have been introduced in structural equation modeling which should work well with much lower sample sizes. The current study reanalyzes the simulation of Meuleman and Billiet using Bayesian estimation to find the lowest number of countries needed when conducting multilevel SEM. The main result of our simulations is that a sample of about 20 countries is sufficient for accurate Bayesian estimation, which makes multilevel SEM practicable for the number of countries commonly available in large scale comparative surveys.},
author = {Hox, Joop and Hox, Joop J.C.M. and van de Schoot, Rens and Matthijsse, Suzette},
doi = {10.18148/srm/2012.v6i2.5033},
journal = {Survey Research Methods},
title = {How few countries will do? Comparative survey analysis from a Bayesian perspective},
year = {2012}
}
@article{Morey2018,
abstract = {Scientific theories explain phenomena using simplifying assumptions?for instance, that the speed of light does not depend on the direction in which the light is moving, or that the shape of a pea plant?s seeds depends on a small number of alleles randomly obtained from its parents. These simplifying assumptions often take the form of statistical null hypotheses; hence, supporting these simplifying assumptions with statistical evidence is crucial to scientific progress, though it might involve ?accepting? a null hypothesis. We review two historical examples in which statistical evidence was used to accept a simplifying assumption (that there is no luminiferous ether and that genetic traits are passed on in discrete forms) and one in which the null hypothesis was not accepted despite repeated failures (gravitational waves), drawing lessons from each. We emphasize the role of the scientific context in acceptance of the null: Accepting a null hypothesis is never a purely statistical affair.},
author = {Morey, Richard D. and Homer, Saskia and Proulx, Travis},
doi = {10.1177/2515245918776023},
issn = {2515-2459},
journal = {Advances in Methods and Practices in Psychological Science},
title = {Beyond Statistics: Accepting the Null Hypothesis in Mature Sciences},
year = {2018}
}
@article{Barr2013,
abstract = {Linear mixed-effects models (LMEMs) have become increasingly prominent in psycholinguistics and related areas. However, many researchers do not seem to appreciate how random effects structures affect the generalizability of an analysis. Here, we argue that researchers using LMEMs for confirmatory hypothesis testing should minimally adhere to the standards that have been in place for many decades. Through theoretical arguments and Monte Carlo simulation, we show that LMEMs generalize best when they include the maximal random effects structure justified by the design. The generalization performance of LMEMs including data-driven random effects structures strongly depends upon modeling criteria and sample size, yielding reasonable results on moderately-sized samples when conservative criteria are used, but with little or no power advantage over maximal models. Finally, random-intercepts-only LMEMs used on within-subjects and/or within-items data from populations where subjects and/or items vary in their sensitivity to experimental manipulations always generalize worse than separate F1 and F2 tests, and in many cases, even worse than F1 alone. Maximal LMEMs should be the 'gold standard' for confirmatory hypothesis testing in psycholinguistics and beyond. {\textcopyright} 2012 Elsevier Inc.},
author = {Barr, Dale J. and Levy, Roger and Scheepers, Christoph and Tily, Harry J.},
doi = {10.1016/j.jml.2012.11.001},
issn = {0749596X},
journal = {Journal of Memory and Language},
keywords = {Generalization,Linear mixed-effects models,Monte Carlo simulation,Statistics},
month = {apr},
number = {3},
pages = {255--278},
pmid = {24403724},
publisher = {Academic Press},
title = {Random effects structure for confirmatory hypothesis testing: Keep it maximal},
url = {https://www.sciencedirect.com/science/article/pii/S0749596X12001180},
volume = {68},
year = {2013}
}
@misc{Frank2018,
author = {Frank, Michael},
booktitle = {Babies Learning Language [blog]},
title = {Mixed effects models: Is it time to go Bayesian by default?},
url = {http://babieslearninglanguage.blogspot.com/2018/02/mixed-effects-models-is-it-time-to-go.html},
year = {2018}
}
@article{Matuschek2017,
abstract = {Linear mixed-effects models have increasingly replaced mixed-model analyses of variance for statistical inference in factorial psycholinguistic experiments. Although LMMs have many advantages over ANOVA, like ANOVAs, setting them up for data analysis also requires some care. One simple option, when numerically possible, is to fit the full variance-covariance structure of random effects (the maximal model; Barr, Levy, Scheepers {\&} Tily, 2013), presumably to keep Type I error down to the nominal $\alpha$ in the presence of random effects. Although it is true that fitting a model with only random intercepts may lead to higher Type I error, fitting a maximal model also has a cost: it can lead to a significant loss of power. We demonstrate this with simulations and suggest that for typical psychological and psycholinguistic data, higher power is achieved without inflating Type I error rate if a model selection criterion is used to select a random effect structure that is supported by the data.},
archivePrefix = {arXiv},
arxivId = {1511.01864},
author = {Matuschek, Hannes and Kliegl, Reinhold and Vasishth, Shravan and Baayen, Harald and Bates, Douglas},
doi = {10.1016/j.jml.2017.01.001},
eprint = {1511.01864},
issn = {0749596X},
journal = {Journal of Memory and Language},
keywords = {Hypothesis testing,Linear mixed effect model,Power},
title = {Balancing Type I error and power in linear mixed models},
year = {2017}
}
@article{Stunnenberg2018,
abstract = {Importance: In rare diseases it is difficult to achieve high-quality evidence of treatment efficacy because of small cohorts and clinical heterogeneity. With emerging treatments for rare diseases, innovative trial designs are needed. Objective: To investigate the effectiveness of mexiletine in nondystrophic myotonia using an aggregated N-of-1 trials design and compare results between this innovative design and a previously conducted RCT. Design, Setting, and Participants: A series of aggregated, double-blind, randomized, placebo-controlled N-of-1-trials, performed in a single academic referral center. Thirty Dutch adult patients with genetically confirmed nondystrophic myotonia (38 patients screened) were enrolled between February 2014 and June 2015. Follow-up was completed in September 2016. Interventions: Mexiletine (600 mg daily) vs placebo during multiple treatment periods of 4 weeks. Main Outcomes and Measures: Reduction in daily-reported muscle stiffness on a scale of 1 to 9, with higher scores indicating more impairment. A Bayesian hierarchical model aggregated individual N-of-1 trial data to determine the posterior probability of reaching a clinically meaningful effect of a greater than 0.75-point difference. Results: Among 30 enrolled patients (mean age, 43.4 [SD, 15.24] years; 22{\%} men; 19 CLCN1 and 11 SCN4A genotype), 27 completed the study and 3 dropped out (1 because of a serious adverse event). In 24 of the 27 completers, a clinically meaningful treatment effect was found. In the Bayesian hierarchical model, mexiletine resulted in a 100{\%} posterior probability of reaching a clinically meaningful reduction in self-reported muscle stiffness for the nondystrophic myotonia group overall and the CLCN1 genotype subgroup and 93{\%} posterior probability for the SCN4A genotype subgroup. In the total nondystrophic myotonia group, the median muscle stiffness score was 6.08 (interquartile range, 4.71-6.80) at baseline and was 2.50 (95{\%} credible interval [CrI], 1.77-3.24) during the mexiletine period and 5.56 (95{\%} CrI, 4.73-6.39) during the placebo period; difference in symptom score reduction, 3.06 (95{\%} CrI, 1.96-4.15; n = 27) favoring mexiletine. The most common adverse event was gastrointestinal discomfort (21 mexiletine [70{\%}], 1 placebo [3{\%}]). One serious adverse event occurred (1 mexiletine [3{\%}]; allergic skin reaction). Using frequentist reanalysis, mexiletine compared with placebo resulted in a mean reduction in daily-reported muscle stiffness of 3.12 (95{\%} CI, 2.46-3.78), consistent with the previous RCT treatment effect of 2.69 (95{\%} CI, 2.12-3.26). Conclusions and Relevance: In a series of N-of-1 trials of mexiletine vs placebo in patients with nondystrophic myotonia, there was a reduction in mean daily-reported muscle stiffness that was consistent with the treatment effect in a previous randomized clinical trial. These findings support the efficacy of mexiletine for treatment of nondystrophic myotonia as well as the feasibility of N-of-1 trials for assessing interventions in some chronic rare diseases. Trial Registration: ClinicalTrials.gov Identifier: NCT02045667.},
author = {Stunnenberg, Bas C. and Raaphorst, Joost and Groenewoud, Hans M. and Statland, Jeffrey M. and Griggs, Robert C. and Woertman, Willem and Stegeman, Dick F. and Timmermans, Janneke and Trivedi, Jaya and Matthews, Emma and Saris, Christiaan G.J. and Schouwenberg, Bas J. and Drost, Gea and {Van Engelen}, Baziel G.M. and {Van Der Wilt}, Gert Jan},
doi = {10.1001/jama.2018.18020},
issn = {15383598},
journal = {JAMA - Journal of the American Medical Association},
mendeley-groups = {Bayes},
title = {Effect of Mexiletine on Muscle Stiffness in Patients with Nondystrophic Myotonia Evaluated Using Aggregated N-of-1 Trials},
year = {2018}
}
@article{VandeSchoot2014,
abstract = {Bayesian statistical methods are becoming ever more popular in applied and fundamental research. In this study a gentle introduction to Bayesian analysis is provided. It is shown under what circumstances it is attractive to use Bayesian estimation, and how to interpret properly the results. First, the ingredients underlying Bayesian methods are introduced using a simplified example. Thereafter, the advantages and pitfalls of the specification of prior knowledge are discussed. To illustrate Bayesian methods explained in this study, in a second example a series of studies that examine the theoretical framework of dynamic interactionism are considered. In the Discussion the advantages and disadvantages of using Bayesian statistics are reviewed, and guidelines on how to report on Bayesian statistics are provided.},
author = {{van de Schoot}, Rens and Kaplan, David and Denissen, Jaap and Asendorpf, Jens B. and Neyer, Franz J. and van Aken, Marcel A.G.},
doi = {10.1111/cdev.12169},
isbn = {1467-8624 (Electronic)$\backslash$r0009-3920 (Linking)},
issn = {14678624},
journal = {Child Development},
mendeley-groups = {Bayes},
number = {3},
pages = {842--860},
pmid = {24116396},
title = {A Gentle Introduction to Bayesian Analysis: Applications to Developmental Research},
volume = {85},
year = {2014}
}
@book{Finch2017,
abstract = {This book is designed primarily for upper level undergraduate and graduate level students taking a course in multilevel modelling and/or statistical modelling with a large multilevel modelling component. The focus is on presenting the theory and practice of major multilevel modelling techniques in a variety of contexts, using Mplus as the software tool, and demonstrating the various functions available for these analyses in Mplus, which is widely used by researchers in various fields, including most of the social sciences. In particular, Mplus offers users a wide array of tools for latent variable modelling, including for multilevel data.},
author = {Finch, W. Holmes and Bolin, Jocelyn E.},
booktitle = {Multilevel Modeling Using Mplus},
doi = {10.1201/9781315165882},
isbn = {9781498748254},
title = {Multilevel modeling using Mplus},
year = {2017}
}
@article{Jarosz2014,
abstract = {The purpose of this paper is to provide an easy template for the inclusion of the Bayes factor in reporting experimental results, particularly as a recommendation for articles in the Journal of Problem Solving. The Bayes factor provides information with a similar purpose to the p-value—to allow the researcher to make statistical inferences from data provided by experiments. While the p-value is widely used, the Bayes factor provides several advantages, particularly in that it allows the researcher to make a statement about the alternative hypothesis, rather than just the null hypothesis. In addition, it provides a clearer estimate of the amount of evidence present in the data. Building on previous work by authors such as Wagenmakers (2007), Rouder et al. (2009), and Masson (2011), this article provides a short introduction to Bayes factors, before providing a practical guide to their computation using examples from published work on problem solving.},
author = {Jarosz, Andrew F. and Wiley, Jennifer},
doi = {10.7771/1932-6246.1167},
issn = {19326246},
journal = {Journal of Problem Solving},
keywords = {Bayes factor,Statistics},
title = {What are the odds? A practical guide to computing and reporting bayes factors},
year = {2014}
}
@article{Gallistel2009,
abstract = {Null hypotheses are simple, precise, and theoretically important. Conventional statistical analysis cannot support them; Bayesian analysis can. The challenge in a Bayesian analysis is to formulate a suitably vague alternative, because the vaguer the alternative is (the more it spreads out the unit mass of prior probability), the more the null is favored. A general solution is a sensitivity analysis: Compute the odds for or against the null as a function of the limit(s) on the vagueness of the alternative. If the odds on the null approach 1 from above as the hypothesized maximum size of the possible effect approaches 0, then the data favor the null over any vaguer alternative to it. The simple computations and the intuitive graphic representation of the analysis are illustrated by the analysis of diverse examples from the current literature. They pose 3 common experimental questions: (a) Are 2 means the same? (b) Is performance at chance? (c) Are factors additive?},
author = {Gallistel, C R},
doi = {10.1037/a0015251},
issn = {0033-295X},
journal = {Psychological review},
keywords = {*Bayes Theorem,*Likelihood Functions,Attention,Behavioral Research/*statistics & numerical data,Conditioning, Classical,Humans,Learning,Psychomotor Performance},
language = {eng},
month = {apr},
number = {2},
pages = {439--453},
title = {{The importance of proving the null}},
url = {https://pubmed.ncbi.nlm.nih.gov/19348549 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2859953/},
volume = {116},
year = {2009}
}
@article{Rindskopf2020,
abstract = {Because of the different philosophy of Bayesian statistics, where parameters are random variables and data are considered fixed, the analysis and presentation of results will differ from that of frequentist statistics. Most importantly, the probabilities that a parameter is in certain regions of the parameter space are crucial quantities in Bayesian statistics that are not calculable (or considered important) in the frequentist approach that is the basis of much of traditional statistics. In this article, I discuss the implications of these differences for presentation of the results of Bayesian analyses. In doing so, I present more detailed guidelines than are usually provided and explain the rationale for my suggestions.},
author = {Rindskopf, David},
doi = {10.1177/0193841X20977619},
issn = {0193-841X},
journal = {Evaluation Review},
month = {dec},
publisher = {SAGE Publications Inc},
title = {{Reporting Bayesian Results}},
url = {https://doi.org/10.1177/0193841X20977619},
year = {2020}
}
@misc{nalborczyk_batailler_loevenbruck_vilain_bürkner_2019,
 title={An Introduction to Bayesian Multilevel Models Using brms: A Case Study of Gender Effects on Vowel Variability in Standard Indonesian},
 url={psyarxiv.com/guhsa},
 DOI={10.1044/2018_JSLHR-S-18-0006},
 publisher={PsyArXiv},
 author={Nalborczyk, Ladislas and Batailler, Cédric and Loevenbruck, Hélène and Vilain, Anne and Bürkner, Paul - Christian},
 year={2019},
 month={May}
}
@article{Smid2020,
author = {Smid, Sanne C and McNeish, Daniel and Mio{\v{c}}evi{\'{c}}, Milica and van de Schoot, Rens},
doi = {10.1080/10705511.2019.1577140},
journal = {Structural Equation Modeling: A Multidisciplinary Journal},
number = {1},
pages = {131--161},
publisher = {Routledge},
title = {{Bayesian Versus Frequentist Estimation for Structural Equation Models in Small Sample Contexts: A Systematic Review}},
url = {https://doi.org/10.1080/10705511.2019.1577140},
volume = {27},
year = {2020}
}
@article{VandeSchoot2015,
abstract = {BackgroundThe analysis of small data sets in longitudinal studies can lead to power issues and often suffers from biased parameter values. These issues can be solved by using Bayesian estimation in conjunction with informative prior distributions. By means of a simulation study and an empirical example concerning posttraumatic stress symptoms (PTSS) following mechanical ventilation in burn survivors, we demonstrate the advantages and potential pitfalls of using Bayesian estimation.MethodsFirst, we show how to specify prior distributions and by means of a sensitivity analysis we demonstrate how to check the exact influence of the prior (mis-) specification. Thereafter, we show by means of a simulation the situations in which the Bayesian approach outperforms the default, maximum likelihood and approach. Finally, we re-analyze empirical data on burn survivors which provided preliminary evidence of an aversive influence of a period of mechanical ventilation on the course of PTSS following burns.ResultsNot suprisingly, maximum likelihood estimation showed insufficient coverage as well as power with very small samples. Only when Bayesian analysis, in conjunction with informative priors, was used power increased to acceptable levels. As expected, we showed that the smaller the sample size the more the results rely on the prior specification.ConclusionWe show that two issues often encountered during analysis of small samples, power and biased parameters, can be solved by including prior information into Bayesian analysis. We argue that the use of informative priors should always be reported together with a sensitivity analysis.},
annote = {doi: 10.3402/ejpt.v6.25216},
author = {{van de Schoot}, Rens and Broere, Joris J and Perryck, Koen H and Zondervan-Zwijnenburg, Mari{\"{e}}lle and van Loey, Nancy E},
doi = {10.3402/ejpt.v6.25216},
issn = {2000-8198},
journal = {European Journal of Psychotraumatology},
month = {dec},
number = {1},
pages = {25216},
publisher = {Taylor & Francis},
title = {{Analyzing small data sets using Bayesian estimation: the case of posttraumatic stress symptoms following mechanical ventilation in burn survivors}},
url = {https://doi.org/10.3402/ejpt.v6.25216},
volume = {6},
year = {2015}
}
@article{McNeish2016,
author = {McNeish, Daniel},
doi = {10.1080/10705511.2016.1186549},
journal = {Structural Equation Modeling: A Multidisciplinary Journal},
mendeley-groups = {Bayes},
number = {5},
pages = {750--773},
publisher = {Routledge},
title = {{On Using Bayesian Methods to Address Small Sample Problems}},
url = {https://doi.org/10.1080/10705511.2016.1186549},
volume = {23},
year = {2016}
}
@article{Oberauer2022,
doi = {doi:10.1177/09567976211046884},
abstract = {Mixed models are gaining popularity in psychology. For frequentist mixed models, previous research showed that excluding random slopes—differences between individuals in the direction and size of an effect—from a model when they are in the data can lead to a substantial increase in false-positive conclusions in null-hypothesis tests. Here, I demonstrated through five simulations that the same is true for Bayesian hypothesis testing with mixed models, which often yield Bayes factors reflecting very strong evidence for a mean effect on the population level even if there was no such effect. Including random slopes in the model largely eliminates the risk of strong false positives but reduces the chance of obtaining strong evidence for true effects. I recommend starting analysis by testing the support for random slopes in the data and removing them from the models only if there is clear evidence against them.},
annote = {PMID: 35357978},
author = {Oberauer, Klaus},
journal = {Psychological Science},
mendeley-groups = {Bayes},
title = {{The Importance of Random Slopes in Mixed Models for Bayesian Hypothesis Testing}},
url = {https://doi.org/10.1177/09567976211046884},
year = {2022}
}
@misc{Muthen2012,
abstract = {This article proposes a new approach to factor analysis and structural equation modeling using Bayesian analysis. The new approach replaces parameter specifications of exact zeros with approximate zeros based on informative, small-variance priors. It is argued that this produces an analysis that better reflects substantive theories. The proposed Bayesian approach is particularly beneficial in applications where parameters are added to a conventional model such that a nonidentified model is obtained if maximum-likelihood estimation is applied. This approach is useful for measurement aspects of latent variable modeling, such as with confirmatory factor analysis, and the measurement part of structural equation modeling. Two application areas are studied, cross-loadings and residual correlations in confirmatory factor analysis. An example using a full structural equation model is also presented, showing an efficient way to find model misspecification. The approach encompasses 3 elements: model testing using posterior predictive checking, model estimation, and model modification. Monte Carlo simulations and real data are analyzed using Mplus. The real-data analyses use data from Holzinger and Swineford's (1939) classic mental abilities study, Big Five personality factor data from a British survey, and science achievement data from the National Educational Longitudinal Study of 1988. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
author = {Muth{\'{e}}n, Bengt and Asparouhov, Tihomir},
journal = {Psychological Methods},
doi = {10.1037/a0026802},
isbn = {1939-1463(Electronic),1082-989X(Print)},
keywords = {*Confirmatory Factor Analysis,*Factor Analysis,*Markov Chains,*Statistical Probability,Structural Equation Modeling},
mendeley-groups = {Bayes},
number = {3},
pages = {313--335},
publisher = {American Psychological Association},
title = {{Bayesian structural equation modeling: A more flexible representation of substantive theory.}},
volume = {17},
year = {2012}
}

