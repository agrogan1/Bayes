@book{Kruschke2014,
abstract = {There is an explosion of interest in Bayesian statistics, primarily because recently created computational methods have finally made Bayesian analysis obtainable to a wide audience. Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan provides an accessible approach to Bayesian data analysis, as material is explained clearly with concrete examples. The book begins with the basics, including essential concepts of probability and random sampling, and gradually progresses to advanced hierarchical modeling methods for realistic data. Included are step-by-step instructions on how to conduct Bayesian data analyses in the popular and free software R and WinBugs. This book is intended for first-year graduate students or advanced undergraduates. It provides a bridge between undergraduate training and modern Bayesian methods for data analysis, which is becoming the accepted research standard. Knowledge of algebra and basic calculus is a prerequisite.},
author = {Kruschke, John K.},
booktitle = {Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan, Second Edition},
doi = {10.1016/B978-0-12-405888-0.09999-2},
isbn = {9780124058880},
mendeley-groups = {Bayes},
month = {jan},
pages = {1--759},
publisher = {Elsevier Science},
title = {{Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan, second edition}},
year = {2014}
}
@article{Burkner2017,
author = {Burkner, Paul-Christian},
doi = {10.18637/jss.v080.i01},
journal = {Journal of Statistical Software},
number = {1},
pages = {1--28},
title = {{brms: An R Package for Bayesian Multilevel Models Using Stan}},
volume = {80},
year = {2017}
}
@article{Burkner2018,
author = {Burkner, Paul-Christian},
journal = {The R Journal},
number = {1},
pages = {395--411},
title = {{Advanced Bayesian Multilevel Modeling with the R Package brms}},
volume = {10},
year = {2018}
}
@article{Hox2012,
abstract = {Meuleman and Billiet (2009) have carried out a simulation study aimed at the question how many countries are needed for accurate multilevel SEM estimation in comparative studies. The authors concluded that a sample of 50 to 100 countries is needed for accurate estimation. Recently, Bayesian estimation methods have been introduced in structural equation modeling which should work well with much lower sample sizes. The current study reanalyzes the simulation of Meuleman and Billiet using Bayesian estimation to find the lowest number of countries needed when conducting multilevel SEM. The main result of our simulations is that a sample of about 20 countries is sufficient for accurate Bayesian estimation, which makes multilevel SEM practicable for the number of countries commonly available in large scale comparative surveys.},
author = {Hox, Joop and Hox, Joop J.C.M. and van de Schoot, Rens and Matthijsse, Suzette},
doi = {10.18148/srm/2012.v6i2.5033},
journal = {Survey Research Methods},
title = {{How few countries will do? Comparative survey analysis from a Bayesian perspective}},
year = {2012}
}
@article{Kruschke2018,
abstract = {In the practice of data analysis, there is a conceptual distinction between hypothesis testing, on the one hand, and estimation with quantified uncertainty on the other. Among frequentists in psychology, a shift of emphasis from hypothesis testing to estimation has been dubbed ``the New Statistics'' (Cumming 2014). A second conceptual distinction is between frequentist methods and Bayesian methods. Our main goal in this article is to explain how Bayesian methods achieve the goals of the New Statistics better than frequentist methods. The article reviews frequentist and Bayesian approaches to hypothesis testing and to estimation with confidence or credible intervals. The article also describes Bayesian approaches to meta-analysis, randomized controlled trials, and power analysis.},
author = {Kruschke, John K and Liddell, Torrin M},
doi = {10.3758/s13423-016-1221-4},
issn = {1531-5320},
journal = {Psychonomic Bulletin {\&} Review},
month = {feb},
number = {1},
pages = {178--206},
title = {{The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective}},
url = {https://doi.org/10.3758/s13423-016-1221-4},
volume = {25},
year = {2018}
}
@article{Morey2018,
abstract = {Scientific theories explain phenomena using simplifying assumptions?for instance, that the speed of light does not depend on the direction in which the light is moving, or that the shape of a pea plant?s seeds depends on a small number of alleles randomly obtained from its parents. These simplifying assumptions often take the form of statistical null hypotheses; hence, supporting these simplifying assumptions with statistical evidence is crucial to scientific progress, though it might involve ?accepting? a null hypothesis. We review two historical examples in which statistical evidence was used to accept a simplifying assumption (that there is no luminiferous ether and that genetic traits are passed on in discrete forms) and one in which the null hypothesis was not accepted despite repeated failures (gravitational waves), drawing lessons from each. We emphasize the role of the scientific context in acceptance of the null: Accepting a null hypothesis is never a purely statistical affair.},
author = {Morey, Richard D. and Homer, Saskia and Proulx, Travis},
doi = {10.1177/2515245918776023},
issn = {2515-2459},
journal = {Advances in Methods and Practices in Psychological Science},
title = {{Beyond Statistics: Accepting the Null Hypothesis in Mature Sciences}},
year = {2018}
}
@article{Barr2013,
abstract = {Linear mixed-effects models (LMEMs) have become increasingly prominent in psycholinguistics and related areas. However, many researchers do not seem to appreciate how random effects structures affect the generalizability of an analysis. Here, we argue that researchers using LMEMs for confirmatory hypothesis testing should minimally adhere to the standards that have been in place for many decades. Through theoretical arguments and Monte Carlo simulation, we show that LMEMs generalize best when they include the maximal random effects structure justified by the design. The generalization performance of LMEMs including data-driven random effects structures strongly depends upon modeling criteria and sample size, yielding reasonable results on moderately-sized samples when conservative criteria are used, but with little or no power advantage over maximal models. Finally, random-intercepts-only LMEMs used on within-subjects and/or within-items data from populations where subjects and/or items vary in their sensitivity to experimental manipulations always generalize worse than separate F1 and F2 tests, and in many cases, even worse than F1 alone. Maximal LMEMs should be the 'gold standard' for confirmatory hypothesis testing in psycholinguistics and beyond. {\textcopyright} 2012 Elsevier Inc.},
author = {Barr, Dale J. and Levy, Roger and Scheepers, Christoph and Tily, Harry J.},
doi = {10.1016/j.jml.2012.11.001},
issn = {0749596X},
journal = {Journal of Memory and Language},
keywords = {Generalization,Linear mixed-effects models,Monte Carlo simulation,Statistics},
month = {apr},
number = {3},
pages = {255--278},
pmid = {24403724},
publisher = {Academic Press},
title = {{Random effects structure for confirmatory hypothesis testing: Keep it maximal}},
url = {https://www.sciencedirect.com/science/article/pii/S0749596X12001180},
volume = {68},
year = {2013}
}

